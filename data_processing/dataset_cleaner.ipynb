{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83efba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d4c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3e037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = SpellChecker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5228dd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"elan_dataset_merged.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55faae21",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = \"elan_cleaned_retained_merged.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7baba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token(gloss, remove=False):\n",
    "    \n",
    "    removed_decorator_start = \"\"\n",
    "    removed_decorator_end = \"\"\n",
    "\n",
    "    if gloss[:8] == \"FBUOY:DS\":\n",
    "        split = gloss.split(':')\n",
    "        if len(split) > 2:\n",
    "            gloss = gloss.split(':')[2]\n",
    "            removed_decorator_start = \"FBUOY \"\n",
    "    elif gloss[:6] == \"FBUOY:\":\n",
    "        split = gloss.split(':')\n",
    "        if len(split) > 1:\n",
    "            gloss = gloss.split(':')[1]\n",
    "            removed_decorator_start = \"FBUOY \"\n",
    "    elif gloss[:6] == \"FUBOY:\":\n",
    "        split = gloss.split(':')\n",
    "        if len(split) > 1:\n",
    "            gloss = gloss.split(':')[1]\n",
    "            removed_decorator_start = \"FBUOY \"\n",
    "    elif gloss[:6] == \"FBOUY:\":\n",
    "        split = gloss.split(':')\n",
    "        if len(split) > 1:\n",
    "            gloss = gloss.split(':')[1]\n",
    "            removed_decorator_start = \"FBUOY \"\n",
    "    elif gloss[:6] == \"GICA):\":\n",
    "        split = gloss.split(':')\n",
    "        if len(split) > 1:\n",
    "            gloss = gloss.split(':')[1]\n",
    "    elif gloss[:6] == \"TBUOY:\":\n",
    "        split = gloss.split(':')\n",
    "        if len(split) > 1:\n",
    "            gloss = gloss.split(':')[1]\n",
    "            removed_decorator_start = \"FBUOY \"\n",
    "    elif gloss[:3] == \"FS:\":\n",
    "        gloss = gloss[3:]\n",
    "        removed_decorator_start = \"FS \"\n",
    "    elif gloss[:3] == \"FB:\":\n",
    "        gloss = gloss[3:]\n",
    "        removed_decorator_start = \"FB \"\n",
    "    elif gloss[:2] == \"DS\":\n",
    "        split = gloss.split(':')\n",
    "        if len(split) > 1:\n",
    "            gloss = gloss.split(':')[1]\n",
    "            removed_decorator_start = \"DS \"\n",
    "    elif gloss[:2] == \"G(\":\n",
    "        split = gloss.split(':')\n",
    "        if len(split) > 1:\n",
    "            gloss = gloss.split(':')[1]\n",
    "    elif gloss[:3] == \"CA:\":\n",
    "        split = gloss.split(':')\n",
    "        if len(split) > 1:\n",
    "            gloss = gloss.split(':')[1]\n",
    "    elif gloss[:3] == \"GA:\":\n",
    "        split = gloss.split(':')\n",
    "        if len(split) > 1:\n",
    "            gloss = gloss.split(':')[1]\n",
    "    elif gloss[:2] == \"G:\":\n",
    "        split = gloss.split(':')\n",
    "        if len(split) > 1:\n",
    "            gloss = gloss.split(':')[1]\n",
    "    elif gloss[:2] == \"M:\":\n",
    "        split = gloss.split(':')\n",
    "        if len(split) > 1:\n",
    "            gloss = gloss.split(':')[1]\n",
    "    elif gloss[:7] == \"FINISH.\":\n",
    "        gloss = \"FINISH\"\n",
    "\n",
    "    index = gloss.find(\"-2H\")\n",
    "    if index != -1:\n",
    "        gloss = gloss[:index]\n",
    "        removed_decorator_end = \" 2H\"\n",
    "    index = gloss.find(\"-1H\")\n",
    "    if index != -1:\n",
    "        gloss = gloss[:index]\n",
    "        removed_decorator_end = \" 1H\"\n",
    "    index = gloss.find(\"2-H\")\n",
    "    if index != -1:\n",
    "        gloss = gloss[:index]\n",
    "        removed_decorator_end = \" 2H\"\n",
    "    index = gloss.find(\"1-H\")\n",
    "    if index != -1:\n",
    "        gloss = gloss[:index]\n",
    "        removed_decorator_end = \" 1H\"\n",
    "\n",
    "    index = gloss.find(\"(\")\n",
    "    if index != -1:\n",
    "        gloss = gloss[:index]\n",
    "    \n",
    "    if remove:\n",
    "        return gloss\n",
    "    return f'{removed_decorator_start}{gloss}{removed_decorator_end}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4609ae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    \n",
    "    sentence = sentence.replace(\"'s\", \" is\")\n",
    "    sentence = sentence.replace(\"n't\", \" not\")\n",
    "    sentence = sentence.replace(\"'d\", \" had\")\n",
    "    sentence = sentence.replace(\"'ll\", \" will\")\n",
    "    sentence = sentence.replace(\"'m\", \" am\")\n",
    "    sentence = sentence.replace(\"'ve\", \" have\")\n",
    "    sentence = sentence.replace(\"'re\", \" are\")\n",
    "    sentence = sentence.replace(\"ahh\", \"\")\n",
    "    sentence = sentence.replace(\"umm\", \"\")\n",
    "    sentence = sentence.replace(\"?\", \" ?\")\n",
    "    sentence = sentence.replace(\"(\", \"\")\n",
    "    sentence = sentence.replace(\")\", \"\")\n",
    "\n",
    "\n",
    "\n",
    "    cleaned_sentence = \"\"\n",
    "    \n",
    "    for char in sentence:\n",
    "        if char.isalpha() or char == \"'\" or char == \"?\":\n",
    "            cleaned_sentence += char\n",
    "        else:\n",
    "            cleaned_sentence += \" \"\n",
    "    \n",
    "    cleaned_sentence = cleaned_sentence.lower()\n",
    "    cleaned_sentence = re.sub(' +', ' ', cleaned_sentence)\n",
    "    \n",
    "    return cleaned_sentence.strip()\n",
    "\n",
    "def should_skip_token(token):\n",
    "    if token[:3] == \"PT:\":\n",
    "        return True\n",
    "    if token[:5] == \"LOOK(\":\n",
    "        return True\n",
    "    if token[:7] == \"PTBUOY:\":\n",
    "        return True\n",
    "        \n",
    "    return False\n",
    "    \n",
    "def clean_tokens(token_sequence):\n",
    "    \n",
    "    token_sequence = token_sequence.replace(\"FALSE-START\", \"\")\n",
    "    token_sequence = token_sequence.replace(\"FALSE START\", \"\")\n",
    "    token_sequence = token_sequence.replace(\"?\", \" ?\")\n",
    "    tokens = token_sequence.strip().split(\" \")\n",
    "    \n",
    "    \n",
    "    cleaned_tokens = []\n",
    "        \n",
    "    for token in tokens:\n",
    "        if token[:3] == \"PT:\":\n",
    "            continue\n",
    "        if token[:5] == \"LOOK(\":\n",
    "            continue\n",
    "        if token[:7] == \"PTBUOY:\":\n",
    "            continue\n",
    "        \n",
    "        token = get_token(token)\n",
    "        \n",
    "        if token in [\"WELL\", \"\", \"AHH\", \"UMM\", \"FSL\", \"PTBUOY\", \"HMM\", \"ERR\", \"PHOOEY\", \"INDETERMINATE\", \"INDECIPHERABLE\"]:\n",
    "            continue\n",
    "\n",
    "        if token[-1].isdigit():\n",
    "            token = token[:-1]\n",
    "\n",
    "        if len(token) < 2:\n",
    "            continue\n",
    "                        \n",
    "        cleaned_tokens.append(token)\n",
    "        \n",
    "    unduped_tokens = []\n",
    "    \n",
    "    for i in range(0, len(cleaned_tokens)):\n",
    "        if (i == 0 or cleaned_tokens[i] != cleaned_tokens[i - 1]) and (i < 2 or cleaned_tokens[i] != cleaned_tokens[i - 2]):\n",
    "            unduped_tokens.append(cleaned_tokens[i].replace(\"-\", \" \"))\n",
    "        \n",
    "    return (\" \".join(unduped_tokens)).upper()\n",
    "\n",
    "def spell_check(sequence, upper):\n",
    "    sequence = sequence.split(\" \")\n",
    "    output = []\n",
    "    for word in sequence:\n",
    "        if upper:\n",
    "            if spell.correction(word):\n",
    "                output.append(spell.correction(word).upper())\n",
    "            else:\n",
    "                output.append(word)\n",
    "        else:\n",
    "            if spell.correction(word):\n",
    "                output.append(spell.correction(word))\n",
    "            else:\n",
    "                output.append(word)\n",
    "    return \" \".join(output)\n",
    "\n",
    "def create_output_file(input_filename, output_filename):\n",
    "    input_file = open(input_filename, \"r\")\n",
    "    output_file = open(output_filename, \"w+\")\n",
    "    lines = input_file.readlines()\n",
    "    \n",
    "    cleaned_lines = []\n",
    "        \n",
    "    for line in lines:\n",
    "        split = line.split(\"\\t\")\n",
    "        \n",
    "        sentence = clean_sentence(clean_sentence(split[0]))\n",
    "        if len(sentence) == 0:\n",
    "            continue\n",
    "#         sentence = spell_check(sentence, False)\n",
    "\n",
    "        \n",
    "        tokens = clean_tokens(clean_tokens(split[1]))\n",
    "        if len(tokens) == 0:\n",
    "            continue\n",
    "#         tokens = spell_check(tokens, True)\n",
    "        \n",
    "        if (len(sentence) == 0 or len(tokens) == 0) or sentence.count(\" \") > 25 or tokens.count(\" \") > 25:\n",
    "            continue\n",
    "            \n",
    "        print(split[1])\n",
    "        print(tokens)\n",
    "        print()\n",
    "        \n",
    "        cleaned_lines.append(f'{clean_sentence(split[0])}\\t{clean_tokens(split[1])}\\n')\n",
    "        \n",
    "    cleaned_lines.sort(key= lambda line: (line.split(\"\\t\")[0].count(\" \")))\n",
    "    \n",
    "    text = \"\"\n",
    "    \n",
    "    for cleaned_line in cleaned_lines:\n",
    "        text += cleaned_line\n",
    "        \n",
    "    output_file.write(text)\n",
    "    output_file.close()\n",
    "    input_file.close()\n",
    "    \n",
    "    return cleaned_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b20803",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = create_output_file(filename, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66cf804",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf6f152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(sentences, index, bins, title, ylabel, xlabel):\n",
    "    sentence_lengths = []\n",
    "\n",
    "    for line in sentences:\n",
    "        sentence = line.split(\"\\t\")\n",
    "        count = sentence[index].count(\" \")\n",
    "        sentence_lengths.append(count + 1)\n",
    "    \n",
    "    plt.figure(figsize=(14,7)) # Make it 14x7 inch\n",
    "    plt.style.use('seaborn-whitegrid') # nice and clean grid\n",
    "\n",
    "    n, bins, patches = plt.hist(sentence_lengths, bins=bins, facecolor='#2ab0ff', edgecolor='#e0e0e0', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "    n = n.astype('int') # it MUST be integer\n",
    "\n",
    "    # Good old loop. Choose colormap of your taste\n",
    "    for i in range(len(patches)):\n",
    "        patches[i].set_facecolor(plt.cm.viridis(n[i]/max(n)))\n",
    "\n",
    "\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b32071",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(sentences, 0, 25, \"\", \"\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eed86a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac7024e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ffa876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340e2972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcb3078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
