{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbc26eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c889a1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"elan_cleaned_lit.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a499ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(filename, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd502755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(filename):\n",
    "    dict = {}\n",
    "    \n",
    "    list = open(filename, \"r\")\n",
    "    \n",
    "    items = list.readlines()\n",
    "    \n",
    "    for word in items:\n",
    "        mapping = word.split(\"\\t\")\n",
    "        word = mapping[0].strip('\\'.,!?:;\"\\n')\n",
    "        if (len(mapping) > 1):\n",
    "            dict[word] = mapping[1].strip('\\'.,!?:;\"\\n')\n",
    "        else:\n",
    "            dict[word] = True\n",
    "        \n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcd762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = create_dict(\"blacklisted.txt\")\n",
    "replace = create_dict(\"bad_spellcheck.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d30eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(filename, \"r\")\n",
    "\n",
    "lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4e7bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lines = []\n",
    "for line in lines:\n",
    "    parts = line.split(\"\\t\")\n",
    "    \n",
    "    sentence = parts[0]\n",
    "    sequence = parts[1]\n",
    "    \n",
    "    new_sentence = []\n",
    "    for word in sentence.split(\" \"):\n",
    "        word = word.strip('\\'.,!:;\"\\n').lower()\n",
    "        if word in blacklist:\n",
    "            continue\n",
    "        new_sentence.append(word)\n",
    "        \n",
    "    new_sequence = []\n",
    "    for token in sequence.split(\" \"):\n",
    "        token = token.strip('\\'.,!:;\"\\n').upper()\n",
    "        if token in blacklist:\n",
    "            continue\n",
    "        new_sequence.append(token)\n",
    "    \n",
    "    new_sentence = \" \".join(new_sentence)\n",
    "    new_sequence = \" \".join(new_sequence)\n",
    "        \n",
    "    new_lines.append(f'{new_sentence}\\t{new_sequence}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e501a0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727f43a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_lines = []\n",
    "\n",
    "for line in new_lines:\n",
    "    parts = line.split(\"\\t\")\n",
    "    sentence = parts[0]\n",
    "    sequence = parts[1]\n",
    "    \n",
    "    new_sentence = []\n",
    "    for word in sentence.split(\" \"):\n",
    "        word = word.strip('\\'.,!:;\"\\n').lower()\n",
    "        if word in replace:\n",
    "            new_sentence.append(replace[word])\n",
    "        else:\n",
    "            new_sentence.append(word)\n",
    "        \n",
    "    new_sequence = []\n",
    "    for token in sequence.split(\" \"):\n",
    "        token = token.strip('\\'.,!:;\"\\n').upper()\n",
    "        if token in replace:\n",
    "            new_sequence.append(replace[token])\n",
    "        else:\n",
    "            new_sequence.append(token)\n",
    "    \n",
    "    new_sentence = \" \".join(new_sentence)\n",
    "    new_sequence = \" \".join(new_sequence)\n",
    "        \n",
    "    mapped_lines.append(f'{new_sentence}\\t{new_sequence}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb4c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mapped_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59148ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spellcheck_lines = []\n",
    "\n",
    "for line in mapped_lines:\n",
    "    parts = line.split(\"\\t\")\n",
    "    sentence = parts[0]\n",
    "    sequence = parts[1]\n",
    "    \n",
    "    new_sentence = []\n",
    "    for word in sentence.split(\" \"):\n",
    "        word = word.strip('\\'.,!:;\"\\n').lower()\n",
    "        correction = spell.correction(word)\n",
    "        if correction != word:\n",
    "            if word in replace:\n",
    "                new_sentence.append(replace[word])\n",
    "            elif correction == 'i' or correction is None:\n",
    "                new_sentence.append(word)\n",
    "            else:\n",
    "                new_sentence.append(correction)\n",
    "        else:\n",
    "            new_sentence.append(word)\n",
    "            \n",
    "    new_sequence = []\n",
    "    for token in sequence.split(\" \"):\n",
    "        token = token.strip('\\'.,!:;\"\\n').upper()\n",
    "        correction = spell.correction(token)\n",
    "        if correction != token:\n",
    "            if token in replace:\n",
    "                new_sequence.append(replace[token])\n",
    "            elif correction == 'i' or correction is None:\n",
    "                new_sequence.append(token)\n",
    "            else:\n",
    "                new_sequence.append(correction)\n",
    "        else:\n",
    "            new_sequence.append(token)\n",
    "            \n",
    "    print(new_sentence)\n",
    "    \n",
    "    new_sentence = \" \".join(new_sentence)\n",
    "    new_sequence = \" \".join(new_sequence)\n",
    "        \n",
    "    spellcheck_lines.append(f'{new_sentence}\\t{new_sequence}')\n",
    "#     print(f'{new_sentence}\\t{new_sequence}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88c7334",
   "metadata": {},
   "outputs": [],
   "source": [
    "spellcheck_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0278db67",
   "metadata": {},
   "outputs": [],
   "source": [
    "space_removed = []\n",
    "\n",
    "for line in spellcheck_lines:\n",
    "    parts = line.split(\"\\t\")\n",
    "    sentence = parts[0]\n",
    "    sequence = parts[1]\n",
    "    \n",
    "    new_sentence = sentence.replace(\" \", \" \")\n",
    "    new_sequence = sequence.replace(\"  \", \" \")\n",
    "    \n",
    "    space_removed.append(f'{new_sentence}\\t{new_sequence}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a2b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "space_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0856e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_removed = []\n",
    "\n",
    "for line in space_removed:\n",
    "    parts = line.split(\"\\t\")\n",
    "    sentence = parts[0].split(\" \")\n",
    "    sequence = parts[1].split(\" \")\n",
    "        \n",
    "    new_sentence = []\n",
    "\n",
    "    for index, word in enumerate(sentence):\n",
    "        \n",
    "        curr = sentence[index].strip('\\'.,!:;\"\\n').lower()\n",
    "        prev = sentence[index - 1].strip('\\'.,!:;\"\\n').lower()\n",
    "        \n",
    "        if index > 0 and prev == curr:\n",
    "            continue\n",
    "        new_sentence.append(word)\n",
    "        \n",
    "    new_sequence = []\n",
    "    \n",
    "    for index, token in enumerate(sequence):\n",
    "        prev = sequence[index].strip('\\'.,!:;\"\\n').upper()\n",
    "        curr = sequence[index - 1].strip('\\'.,!:;\"\\n').upper()\n",
    "        \n",
    "        if index > 0 and prev == curr:\n",
    "            continue\n",
    "        new_sequence.append(token)\n",
    "                        \n",
    "    new_sentence = \" \".join(new_sentence)\n",
    "    new_sequence = \" \".join(new_sequence)\n",
    "    \n",
    "    duplicate_removed.append(f'{new_sentence}\\t{new_sequence}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9041e1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fe112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = \"elan_cleaned_lit_nodup_spellcheck.txt\"\n",
    "output = open(output_filename, \"w+\")\n",
    "\n",
    "for line in duplicate_removed:\n",
    "    if \"indecipherable\" in line:\n",
    "        continue\n",
    "    output.write(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1747dae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
